{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68dbe7ba-3dce-4c24-b576-e41101ab05c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4665e8-e781-4d00-8f39-07ddad81ac1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30e48e22-397d-49d1-a5a1-164823d03ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torchvision.datasets.CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e60ea920-2fec-4d0c-9454-856c5e3f1631",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 170M/170M [00:41<00:00, 4.07MB/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = torchvision.datasets.CIFAR10(root=\"./data\", train=True, transform=transform, download=True)\n",
    "test_data = torchvision.datasets.CIFAR10(root=\"./data\", train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5db7029-a733-4e73-8f85-e7babd823461",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57db75a1-4556-4b20-861c-dc2a6a0ba5fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5373, -0.6627, -0.6078,  ...,  0.2392,  0.1922,  0.1608],\n",
       "         [-0.8745, -1.0000, -0.8588,  ..., -0.0353, -0.0667, -0.0431],\n",
       "         [-0.8039, -0.8745, -0.6157,  ..., -0.0745, -0.0588, -0.1451],\n",
       "         ...,\n",
       "         [ 0.6314,  0.5765,  0.5529,  ...,  0.2549, -0.5608, -0.5843],\n",
       "         [ 0.4118,  0.3569,  0.4588,  ...,  0.4431, -0.2392, -0.3490],\n",
       "         [ 0.3882,  0.3176,  0.4039,  ...,  0.6941,  0.1843, -0.0353]],\n",
       "\n",
       "        [[-0.5137, -0.6392, -0.6235,  ...,  0.0353, -0.0196, -0.0275],\n",
       "         [-0.8431, -1.0000, -0.9373,  ..., -0.3098, -0.3490, -0.3176],\n",
       "         [-0.8118, -0.9451, -0.7882,  ..., -0.3412, -0.3412, -0.4275],\n",
       "         ...,\n",
       "         [ 0.3333,  0.2000,  0.2627,  ...,  0.0431, -0.7569, -0.7333],\n",
       "         [ 0.0902, -0.0353,  0.1294,  ...,  0.1608, -0.5137, -0.5843],\n",
       "         [ 0.1294,  0.0118,  0.1137,  ...,  0.4431, -0.0745, -0.2784]],\n",
       "\n",
       "        [[-0.5059, -0.6471, -0.6627,  ..., -0.1529, -0.2000, -0.1922],\n",
       "         [-0.8431, -1.0000, -1.0000,  ..., -0.5686, -0.6078, -0.5529],\n",
       "         [-0.8353, -1.0000, -0.9373,  ..., -0.6078, -0.6078, -0.6706],\n",
       "         ...,\n",
       "         [-0.2471, -0.7333, -0.7961,  ..., -0.4510, -0.9451, -0.8431],\n",
       "         [-0.2471, -0.6706, -0.7647,  ..., -0.2627, -0.7333, -0.7333],\n",
       "         [-0.0902, -0.2627, -0.3176,  ...,  0.0980, -0.3412, -0.4353]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44d4752b-3a0e-4477-8602-c067479dcfbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2beee28-37f0-4ddd-8713-1b0ee969afe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29dd76f5-ca85-49ac-afe2-c4abc6a30de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 12, 5)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(12, 24, 5)\n",
    "        self.fc1 = nn.Linear(24 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30169ae7-5932-4701-8b11-efb0b5d0bd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNet()\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3562d44-1ba6-4aba-9797-462e38da2802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch  0...\n",
      "Loss: 2.2172\n",
      "Training epoch  1...\n",
      "Loss: 1.8027\n",
      "Training epoch  2...\n",
      "Loss: 1.5673\n",
      "Training epoch  3...\n",
      "Loss: 1.4453\n",
      "Training epoch  4...\n",
      "Loss: 1.3563\n",
      "Training epoch  5...\n",
      "Loss: 1.2749\n",
      "Training epoch  6...\n",
      "Loss: 1.2036\n",
      "Training epoch  7...\n",
      "Loss: 1.1362\n",
      "Training epoch  8...\n",
      "Loss: 1.0768\n",
      "Training epoch  9...\n",
      "Loss: 1.0217\n",
      "Training epoch  10...\n",
      "Loss: 0.9789\n",
      "Training epoch  11...\n",
      "Loss: 0.9400\n",
      "Training epoch  12...\n",
      "Loss: 0.9031\n",
      "Training epoch  13...\n",
      "Loss: 0.8702\n",
      "Training epoch  14...\n",
      "Loss: 0.8376\n",
      "Training epoch  15...\n",
      "Loss: 0.8050\n",
      "Training epoch  16...\n",
      "Loss: 0.7752\n",
      "Training epoch  17...\n",
      "Loss: 0.7477\n",
      "Training epoch  18...\n",
      "Loss: 0.7197\n",
      "Training epoch  19...\n",
      "Loss: 0.6988\n",
      "Training epoch  20...\n",
      "Loss: 0.6721\n",
      "Training epoch  21...\n",
      "Loss: 0.6485\n",
      "Training epoch  22...\n",
      "Loss: 0.6242\n",
      "Training epoch  23...\n",
      "Loss: 0.6032\n",
      "Training epoch  24...\n",
      "Loss: 0.5814\n",
      "Training epoch  25...\n",
      "Loss: 0.5625\n",
      "Training epoch  26...\n",
      "Loss: 0.5430\n",
      "Training epoch  27...\n",
      "Loss: 0.5185\n",
      "Training epoch  28...\n",
      "Loss: 0.5014\n",
      "Training epoch  29...\n",
      "Loss: 0.4781\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    print(f'Training epoch  {epoch}...')\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Loss: {running_loss / len(train_loader):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a12fb6e-5109-42c4-bb4c-9b0fccfb8759",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'trained_net.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd0b0a19-596d-4c2c-99a9-20d48dabeb03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = NeuralNet()\n",
    "net.load_state_dict(torch.load('trained_net.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d95fbe23-7db3-4f3e-b356-c83b018aa88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 67.86%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = (correct/total)*100\n",
    "print(f'Accuracy: {accuracy}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "431a199e-8a19-422d-829c-f800527b882c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction is cat\n",
      "Prediction is dog\n"
     ]
    }
   ],
   "source": [
    "new_transform = transforms.Compose([\n",
    "    transforms.Resize((32,32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5,0.5,0.5))\n",
    "])\n",
    "\n",
    "def load_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image = new_transform(image)\n",
    "    image = image.unsqueeze(0)\n",
    "    return image\n",
    "\n",
    "image_paths = ['cat.jpeg', 'dog.jpeg']\n",
    "images = [load_image(img) for img in image_paths]\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for image in images:\n",
    "        output = net(image)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        print(f'Prediction is {class_names[predicted.item()]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a500d5e-5ae8-4d2e-b28a-a7c1136e7271",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
