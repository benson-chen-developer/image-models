{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68dbe7ba-3dce-4c24-b576-e41101ab05c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from bing_image_downloader import downloader\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import os, shutil\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "from duckduckgo_search import DDGS\n",
    "import httpx\n",
    "import requests, os, random, shutil\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69de44ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: 170/200\n",
      "✅ Download done.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Download the data images\"\"\"\n",
    "\n",
    "#returns this\n",
    "# \"title\": \"File:The Sun by the Atmospheric Imaging Assembly of NASA's Solar ...\",\n",
    "# \"image\": \"https://upload.wikimedia.org/wikipedia/commons/b/b4/The_Sun_by_the_Atmospheric_Imaging_Assembly_of_NASA's_Solar_Dynamics_Observatory_-_20100819.jpg\",\n",
    "# \"thumbnail\": \"https://tse4.mm.bing.net/th?id=OIP.lNgpqGl16U0ft3rS8TdFcgEsEe&pid=Api\",\n",
    "# \"url\": \"https://en.wikipedia.org/wiki/File:The_Sun_by_the_Atmospheric_Imaging_Assembly_of_NASA's_Solar_Dynamics_Observatory_-_20100819.jpg\",\n",
    "# \"height\": 3860,\n",
    "# \"width\": 4044,\n",
    "# \"source\": \"Bing\",\n",
    "\n",
    "search_query = \"Barack Obama\"\n",
    "\n",
    "results = DDGS().images(\n",
    "    keywords=search_query,\n",
    "    region=\"wt-wt\",\n",
    "    safesearch=\"off\",\n",
    "    size=None,\n",
    "    color=None,\n",
    "    type_image=None,\n",
    "    layout=None,\n",
    "    license_image=None,\n",
    "    max_results=200,\n",
    ")\n",
    "\n",
    "#Using httpx, download each image from the results.image field of duckduckgo\n",
    "valid_exts = ('png', 'jpg', 'jpeg')\n",
    "downloaded = 0\n",
    "for i, result in enumerate(results):\n",
    "    try:\n",
    "        image_url = result['image']\n",
    "        ext = image_url.split('.')[-1].split('?')[0].lower()  # get extension and lowercase it\n",
    "        \n",
    "        if ext not in valid_exts:\n",
    "            # Skip if not an allowed image type\n",
    "            continue\n",
    "        \n",
    "        response = httpx.get(image_url, timeout=10)\n",
    "        if response.status_code != 200:\n",
    "            continue\n",
    "        \n",
    "        filename = f'img{i}.{ext}'\n",
    "        with open(f'./images/{filename}', 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        \n",
    "        downloaded += 1\n",
    "        print(f'Downloaded: {downloaded}/{len(results)}', end='\\r')  # progress on one line\n",
    "        \n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "print('\\n✅ Download done.')\n",
    "\n",
    "#Once the images are downloaded half will get moved to train and half to test\n",
    "src_folder = Path(\"images\")\n",
    "train_folder = Path(f'data/train/{search_query}')\n",
    "test_folder = Path(f'data/test/{search_query}')\n",
    "train_folder.mkdir(parents=True, exist_ok=True)\n",
    "test_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "all_images = list(src_folder.glob(\"*\"))\n",
    "random.shuffle(all_images)\n",
    "\n",
    "# Part you move the images to data folders\n",
    "amountInTrain = 100 #Amount you put in train and rest in test\n",
    "for i, img_path in enumerate(all_images):\n",
    "    if i < amountInTrain:\n",
    "        shutil.move(str(img_path), train_folder / img_path.name)\n",
    "    else:\n",
    "        shutil.move(str(img_path), test_folder / img_path.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "de4665e8-e781-4d00-8f39-07ddad81ac1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforms the images to the same, correct size\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "30e48e22-397d-49d1-a5a1-164823d03ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torchvision.datasets.CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e60ea920-2fec-4d0c-9454-856c5e3f1631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load your custom dataset using ImageFolder\n",
    "train_data = ImageFolder(root=\"data/train\", transform=transform)\n",
    "test_data = ImageFolder(root=\"data/test\", transform=transform)\n",
    "\n",
    "# 3. Create data loaders\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e2beee28-37f0-4ddd-8713-1b0ee969afe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Barack Obama']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "29dd76f5-ca85-49ac-afe2-c4abc6a30de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 12, 5)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(12, 24, 5)\n",
    "        self.fc1 = nn.Linear(24 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "30169ae7-5932-4701-8b11-efb0b5d0bd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNet()\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b3562d44-1ba6-4aba-9797-462e38da2802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch  0...\n",
      "Loss: 2.3903\n",
      "Training epoch  1...\n",
      "Loss: 2.3710\n",
      "Training epoch  2...\n",
      "Loss: 2.3411\n",
      "Training epoch  3...\n",
      "Loss: 2.3014\n",
      "Training epoch  4...\n",
      "Loss: 2.2588\n",
      "Training epoch  5...\n",
      "Loss: 2.2123\n",
      "Training epoch  6...\n",
      "Loss: 2.1624\n",
      "Training epoch  7...\n",
      "Loss: 2.1112\n",
      "Training epoch  8...\n",
      "Loss: 2.0609\n",
      "Training epoch  9...\n",
      "Loss: 2.0070\n",
      "Training epoch  10...\n",
      "Loss: 1.9519\n",
      "Training epoch  11...\n",
      "Loss: 1.8910\n",
      "Training epoch  12...\n",
      "Loss: 1.8248\n",
      "Training epoch  13...\n",
      "Loss: 1.7556\n",
      "Training epoch  14...\n",
      "Loss: 1.6785\n",
      "Training epoch  15...\n",
      "Loss: 1.5839\n",
      "Training epoch  16...\n",
      "Loss: 1.4707\n",
      "Training epoch  17...\n",
      "Loss: 1.3322\n",
      "Training epoch  18...\n",
      "Loss: 1.1344\n",
      "Training epoch  19...\n",
      "Loss: 0.8693\n",
      "Training epoch  20...\n",
      "Loss: 0.5178\n",
      "Training epoch  21...\n",
      "Loss: 0.2317\n",
      "Training epoch  22...\n",
      "Loss: 0.0730\n",
      "Training epoch  23...\n",
      "Loss: 0.0245\n",
      "Training epoch  24...\n",
      "Loss: 0.0088\n",
      "Training epoch  25...\n",
      "Loss: 0.0046\n",
      "Training epoch  26...\n",
      "Loss: 0.0028\n",
      "Training epoch  27...\n",
      "Loss: 0.0019\n",
      "Training epoch  28...\n",
      "Loss: 0.0015\n",
      "Training epoch  29...\n",
      "Loss: 0.0013\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    print(f'Training epoch  {epoch}...')\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Loss: {running_loss / len(train_loader):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9a12fb6e-5109-42c4-bb4c-9b0fccfb8759",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'trained_net.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bd0b0a19-596d-4c2c-99a9-20d48dabeb03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = NeuralNet()\n",
    "net.load_state_dict(torch.load('trained_net.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d95fbe23-7db3-4f3e-b356-c83b018aa88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = (correct/total)*100\n",
    "print(f'Accuracy: {accuracy}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431a199e-8a19-422d-829c-f800527b882c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b2.png → Prediction: Barack Obama\n",
      "b1.png → Prediction: Barack Obama\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "# Define transform to match training\n",
    "new_transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Function to load and transform image\n",
    "def load_image(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")  # ensure 3 channels\n",
    "    image = new_transform(image)\n",
    "    image = image.unsqueeze(0)  # add batch dimension\n",
    "    return image\n",
    "\n",
    "# Load all images in guess_images folder\n",
    "guess_folder = Path(\"guess_images\")\n",
    "image_paths = list(guess_folder.glob(\"*.[jp][pn]g\"))  # jpg/jpeg/png\n",
    "\n",
    "# Predict\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for img_path in image_paths:\n",
    "        image_tensor = load_image(img_path)\n",
    "        output = net(image_tensor)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        print(f\"{img_path.name} → Prediction: {class_names[predicted.item()]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a500d5e-5ae8-4d2e-b28a-a7c1136e7271",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
